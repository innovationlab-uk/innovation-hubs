{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "flexible-prince",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "blind-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os, time, pickle\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "needed-hunter",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Twitter:\n",
    "    def __init__(self, username, password):\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        self.driver = webdriver.Firefox()\n",
    "        self.url = \"https://twitter.com/\"\n",
    "        \n",
    "        self.driver.implicitly_wait(1)\n",
    "        self.init_twitter_state = self.login()\n",
    "        \n",
    "    def get_driver(self):\n",
    "        \"\"\"\n",
    "        Returns the geckodriver instance for this class.\n",
    "        \"\"\"\n",
    "        return self.driver\n",
    "    \n",
    "    def login(self):\n",
    "        \"\"\" Login to Twitter \"\"\"\n",
    "        try:\n",
    "            self.driver.get(self.url + \"login\")\n",
    "            username_field = self.driver.find_element_by_name(\"session[username_or_email]\")\n",
    "            password_field = self.driver.find_element_by_name(\"session[password]\")\n",
    "            username_field.send_keys(self.username)\n",
    "            self.driver.implicitly_wait(1)\n",
    "            password_field.send_keys(self.password)\n",
    "            self.driver.implicitly_wait(1)\n",
    "            password_field.submit()\n",
    "            return True\n",
    "        except:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "soviet-kingston",
   "metadata": {},
   "outputs": [],
   "source": [
    "class User:\n",
    "    def __init__(self, tag, twitter):\n",
    "        self.tag = tag\n",
    "        self.followers = set()\n",
    "        self.following = set()\n",
    "        self.twitter = twitter\n",
    "        self.driver = twitter.get_driver()\n",
    "        self.init_twitter_state = twitter.init_twitter_state\n",
    "    \n",
    "    \"\"\"\n",
    "    def init_twitter(self):\n",
    "        if(self.init_twitter_state is False):\n",
    "            twitter = Twitter()\n",
    "            self.driver = twitter.get_driver()\n",
    "            self.init_twitter_state = twitter.login()\n",
    "    \"\"\"\n",
    "    def scrape_following(self):\n",
    "        self.scrape_followx(\"Following\")\n",
    "\n",
    "    def scrape_followers(self):\n",
    "        self.scrape_followx(\"Followers\")\n",
    "    \n",
    "    def scrape_followx(self, fx):\n",
    "        \"\"\"\n",
    "        Scrape the followers from a given user.\n",
    "        \"\"\"\n",
    "        if(self.tag is None or self.init_twitter_state is False):\n",
    "            return\n",
    "    \n",
    "        url = f\"https://twitter.com/{self.tag}/{fx.lower()}\"\n",
    "        self.driver.get(url)\n",
    "        self.driver.implicitly_wait(2)\n",
    "\n",
    "        SCROLL_PAUSE_TIME = 1\n",
    "\n",
    "        # Get scroll height\n",
    "        last_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        self.driver.implicitly_wait(1)\n",
    "\n",
    "        while True:\n",
    "            followx_els = self.get_followx_html(fx)\n",
    "            self.serialize_followx(followx_els)\n",
    "            # Scroll down to bottom\n",
    "            self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "            # Wait to load page\n",
    "            time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "            # Calculate new scroll height and compare with last scroll height\n",
    "            new_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "            if(len(self.followers) % 200) == 0:\n",
    "                print(f\"We have {len(self.followers)} followers.\")\n",
    "            \n",
    "    def get_followx_html(self, fx):\n",
    "        \"\"\"\n",
    "        Ask the driver to get an update view of the HTML\n",
    "        :returns followx_els a list of soup items, they are the followers\n",
    "        \"\"\"\n",
    "        followx_html = self.driver.find_elements_by_xpath(f\"//div[@aria-label='Timeline: {fx}']\")[0].get_attribute('innerHTML')\n",
    "        soup = BeautifulSoup(followx_html, \"html.parser\")\n",
    "        return soup.div.findChildren(\"div\" , recursive=False)\n",
    "\n",
    "    def serialize_followx(self, followx_els):\n",
    "        \"\"\"\n",
    "        Converts the soup html into a dictionary \n",
    "        :params followers_els Twitter div components of the followers\n",
    "        \"\"\"\n",
    "        followx = {}\n",
    "        for c in followx_els:\n",
    "            try:\n",
    "                self.followers.add(str(c.a['href']))\n",
    "                followx[c.a['href']] = {\n",
    "                    'url_tag': c.a['href'],\n",
    "                    'tag': c.span.text,\n",
    "                    'profile_img': c.a.img['src'],\n",
    "                    'profile_text': c.findAll('span')[-1].text\n",
    "                }\n",
    "            except:\n",
    "                pass\n",
    "        return followx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fancy-ready",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwitterSearch:\n",
    "    def __init__(self, terms, twitter):\n",
    "        \"\"\"\n",
    "        :terms ['term1', 'term2'] A list of search terms\n",
    "        \"\"\"\n",
    "        self.terms = terms\n",
    "        self.twitter = twitter\n",
    "        self.driver = twitter.get_driver()\n",
    "        self.init_twitter_state = twitter.init_twitter_state\n",
    "        self.tweets = set()\n",
    "        \n",
    "    def get_search_html(self):\n",
    "        \"\"\"\n",
    "        Ask the driver to get an update view of the HTML\n",
    "        :returns\n",
    "        \"\"\"\n",
    "        timeline_html = self.driver.find_elements_by_xpath(\"//div[@aria-label='Timeline: Search timeline']\")[0].get_attribute('innerHTML')\n",
    "        soup = BeautifulSoup(timeline_html, \"html.parser\")\n",
    "        return soup.div.findChildren(\"div\" , recursive=False)\n",
    "\n",
    "    def serialize_tweets(self, search_els):\n",
    "        \"\"\"\n",
    "        Converts the soup html into a dictionary \n",
    "        :\n",
    "        \"\"\"\n",
    "        for t in search_els:\n",
    "            try:\n",
    "                tweet_text = t.find('article').text\n",
    "                tweet = {\n",
    "                    \"user_tag\": tweet_text.split('@', 1)[0],\n",
    "                    \"user_name\": tweet_text.split('@', 1)[1].split('·', 1)[0],\n",
    "                    \"tweet_link\": [i['href'] for i in t.article.findAll('a') if \"/status/\" in i['href']][0],\n",
    "                    \"tweet\": tweet_text.split('@', 1)[1].split('·', 1)[1]\n",
    "                }\n",
    "                self.tweets.add(json.dumps(tweet))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    \n",
    "    def get_search_url(self):\n",
    "        \"\"\"\n",
    "        Creates the search URL from the search terms and twitter URL.\n",
    "        \"\"\"\n",
    "        search_terms = \" \".join(self.terms)\n",
    "        return f\"{self.twitter.url}/search?q={search_terms}&src=typed_query&f=live\"\n",
    "            \n",
    "    def search(self):\n",
    "        if(self.terms is None or self.init_twitter_state is False):\n",
    "            return\n",
    "    \n",
    "        search_url = self.get_search_url()\n",
    "        self.driver.get(search_url)\n",
    "        time.sleep(2)\n",
    "        self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        self.driver.implicitly_wait(1)\n",
    "        \n",
    "        SCROLL_PAUSE_TIME = 1\n",
    "\n",
    "        # Get scroll height\n",
    "        last_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        self.driver.implicitly_wait(1)\n",
    "\n",
    "        while True:\n",
    "            search_els = self.get_search_html()\n",
    "            self.serialize_tweets(search_els)\n",
    "            # Scroll down to bottom\n",
    "            self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "            # Wait to load page\n",
    "            time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "            # Calculate new scroll height and compare with last scroll height\n",
    "            new_height = self.driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "            if(len(self.tweets) > 20):\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "informal-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use python-dotenv to create an .env file with your credentials.\n",
    "twitter_username = os.getenv(\"TWITTER_USERNAME\")\n",
    "twitter_password = os.getenv(\"TWITTER_PASSWORD\")\n",
    "twitter = Twitter(twitter_username, twitter_password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "taken-toner",
   "metadata": {},
   "outputs": [],
   "source": [
    "ktn = User(\"KTNUK\", twitter)\n",
    "idealdn = User(\"IDEALondon\", twitter)\n",
    "elabs = User(\"eagle_labs\", twitter)\n",
    "cx = User(\"conceptionxtech\", twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "imperial-electric",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 200 followers.\n",
      "We have 400 followers.\n",
      "We have 600 followers.\n",
      "We have 800 followers.\n",
      "We have 1000 followers.\n",
      "We have 1200 followers.\n",
      "We have 1400 followers.\n",
      "We have 1600 followers.\n",
      "We have 2000 followers.\n",
      "We have 2200 followers.\n",
      "We have 2600 followers.\n",
      "We have 2800 followers.\n",
      "We have 3000 followers.\n",
      "We have 3200 followers.\n"
     ]
    }
   ],
   "source": [
    "elabs.scrape_following()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "pressing-qatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('elabs_followings.txt', 'wb') as fp:\n",
    "    pickle.dump(elabs.followers, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "billion-butler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/CJBS_EC',\n",
       " '/DigiCatapult',\n",
       " '/Digicatbrighton',\n",
       " '/FabLabLondon',\n",
       " '/LMarks',\n",
       " '/MarijaButkovic',\n",
       " '/NestaChallenges',\n",
       " '/Plexalcity',\n",
       " '/RAEng_Hub',\n",
       " '/SamanthaRose83',\n",
       " '/TechNation',\n",
       " '/UKBAngels',\n",
       " '/angelacademe',\n",
       " '/beisgovuk',\n",
       " '/bev_vincent',\n",
       " '/capenterprise',\n",
       " '/cgledhill',\n",
       " '/e_nation',\n",
       " '/iamstartacus',\n",
       " '/innobham',\n",
       " '/innovateuk',\n",
       " '/mialomo',\n",
       " '/naomitimperley',\n",
       " '/nesta_uk',\n",
       " '/paolacuneo',\n",
       " '/pitchatpalace',\n",
       " '/stbaasch',\n",
       " '/techUK',\n",
       " '/techcityinsider',\n",
       " '/techdotlondon',\n",
       " '/timothy_barnes',\n",
       " '/tradegovuk'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elabs.followers.intersection(idealdn.followers).intersection(ktn.followers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
